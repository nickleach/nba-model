{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backfill season data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d78339e-5e3d-40c0-bfae-0312bf05b700",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "\n",
    "def fetch_nba_games_and_stats(season_year):\n",
    "    # Base URL for the balldontlie API\n",
    "    games_url = \"https://www.balldontlie.io/api/v1/games\"\n",
    "    stats_url = \"https://www.balldontlie.io/api/v1/stats\"\n",
    "\n",
    "    # Set start_date and end_date for the given season\n",
    "    start_date = datetime(season_year, 10, 24)\n",
    "    end_date = datetime(season_year + 1, 7, 1)  # Assuming season ends by July 1st\n",
    "\n",
    "    # Format dates in the required format (YYYY-MM-DD)\n",
    "    start_date_str = start_date.strftime(\"%Y-%m-%d\")\n",
    "    end_date_str = end_date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    # Initialize variables for pagination\n",
    "    all_games = []\n",
    "    all_stats = []\n",
    "    games_page = 1\n",
    "    games_per_page = 100  # Maximum value as per the API documentation\n",
    "    games_total_pages = 1  # Placeholder, will be updated after the first request\n",
    "\n",
    "    # Fetch games\n",
    "    while games_page <= games_total_pages:\n",
    "        params = {\n",
    "            \"start_date\": start_date_str,\n",
    "            \"end_date\": end_date_str,\n",
    "            \"per_page\": games_per_page,\n",
    "            \"page\": games_page\n",
    "        }\n",
    "\n",
    "        response = requests.get(games_url, params=params)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            all_games.extend(data['data'])\n",
    "\n",
    "            if games_page == 1:\n",
    "                games_total_pages = data['meta']['total_pages']\n",
    "\n",
    "            games_page += 1\n",
    "\n",
    "    # Fetch stats for each game\n",
    "    for game in all_games:\n",
    "        game_id = game['id']\n",
    "        stats_page = 1\n",
    "        stats_per_page = 100\n",
    "        stats_total_pages = 1\n",
    "\n",
    "        while stats_page <= stats_total_pages:\n",
    "            params = {\n",
    "                \"game_ids[]\": game_id,\n",
    "                \"per_page\": stats_per_page,\n",
    "                \"page\": stats_page\n",
    "            }\n",
    "\n",
    "            response = requests.get(stats_url, params=params)\n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "                all_stats.extend(data['data'])\n",
    "\n",
    "                if stats_page == 1:\n",
    "                    stats_total_pages = data['meta']['total_pages']\n",
    "\n",
    "                stats_page += 1\n",
    "\n",
    "    # Merge games and stats with flattened structure\n",
    "    merged_data = []\n",
    "    for stat in all_stats:\n",
    "        game_info = next((game for game in all_games if game['id'] == stat['game']['id']), None)\n",
    "        if game_info:\n",
    "            # Flatten the game, player, team, home_team, and visitor_team data\n",
    "            flattened_game_info = {f'game_{k}': v for k, v in game_info.items() if k != 'home_team' and k != 'visitor_team'}\n",
    "            flattened_player_info = {f'player_{k}': v for k, v in stat['player'].items()}\n",
    "            flattened_team_info = {f'player_team_{k}': v for k, v in stat['team'].items()}\n",
    "            flattened_home_team_info = {f'home_team_{k}': v for k, v in game_info['home_team'].items()}\n",
    "            flattened_visitor_team_info = {f'visitor_team_{k}': v for k, v in game_info['visitor_team'].items()}\n",
    "\n",
    "            # Merge all flattened data\n",
    "            merged_entry = {**flattened_game_info, **flattened_player_info, **flattened_team_info, **flattened_home_team_info, **flattened_visitor_team_info, **stat}\n",
    "            merged_data.append(merged_entry)\n",
    "\n",
    "    return merged_data\n",
    "\n",
    "# Fetch all NBA games and stats for the past 5 seasons\n",
    "current_year = datetime.now().year if datetime.now().month >= 10 else datetime.now().year - 1\n",
    "all_seasons_data = []\n",
    "\n",
    "for season_year in range(current_year, current_year - 3, -1):\n",
    "    season_data = fetch_nba_games_and_stats(season_year)\n",
    "    all_seasons_data.extend(season_data)\n",
    "\n",
    "# You can convert the data into a DataFrame or process it as needed\n",
    "df = pd.DataFrame(all_seasons_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "592bb973-825c-44c0-a24d-d83f01551a1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./nba_games.csv'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(merged_data)\n",
    "\n",
    "# Export to CSV\n",
    "csv_filename = './nba_games_historical.csv'\n",
    "df.to_csv(csv_filename, index=False)\n",
    "\n",
    "csv_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1172195e-0a40-4ac8-96ff-2d3e89530326",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './nba_games.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Load the original dataset\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m nba_data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./nba_games.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Replace with your file path\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Aggregate player statistics for each team in each game\u001b[39;00m\n\u001b[1;32m      7\u001b[0m team_game_stats \u001b[38;5;241m=\u001b[39m nba_data\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgame_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplayer_team_id\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39magg({\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mast\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblk\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mturnover\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     27\u001b[0m })\u001b[38;5;241m.\u001b[39mreset_index()\n",
      "File \u001b[0;32m/usr/local/Caskroom/mambaforge/base/lib/python3.10/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/Caskroom/mambaforge/base/lib/python3.10/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/usr/local/Caskroom/mambaforge/base/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/Caskroom/mambaforge/base/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/usr/local/Caskroom/mambaforge/base/lib/python3.10/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './nba_games.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the original dataset\n",
    "nba_data = pd.read_csv('./nba_games_historical.csv')  # Replace with your file path\n",
    "\n",
    "# Aggregate player statistics for each team in each game\n",
    "team_game_stats = nba_data.groupby(['game_id', 'player_team_id']).agg({\n",
    "    'ast': 'sum', \n",
    "    'blk': 'sum', \n",
    "    'dreb': 'sum', \n",
    "    'fg3_pct': 'mean', \n",
    "    'fg3a': 'sum', \n",
    "    'fg3m': 'sum',\n",
    "    'fg_pct': 'mean', \n",
    "    'fga': 'sum', \n",
    "    'fgm': 'sum', \n",
    "    'ft_pct': 'mean', \n",
    "    'fta': 'sum', \n",
    "    'ftm': 'sum', \n",
    "    'min': 'sum', \n",
    "    'oreb': 'sum', \n",
    "    'pf': 'sum', \n",
    "    'pts': 'sum', \n",
    "    'reb': 'sum', \n",
    "    'stl': 'sum', \n",
    "    'turnover': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "# Extract team meta information\n",
    "team_meta = nba_data[['player_team_id', 'player_team_abbreviation', 'player_team_city', 'player_team_conference', 'player_team_division', 'player_team_full_name', 'player_team_name']].drop_duplicates()\n",
    "\n",
    "# Merge team stats with team meta information\n",
    "team_game_stats = pd.merge(team_game_stats, team_meta, left_on='player_team_id', right_on='player_team_id', how='left')\n",
    "\n",
    "# Separating home and visitor team stats\n",
    "home_team_stats = team_game_stats.add_suffix('_home')\n",
    "visitor_team_stats = team_game_stats.add_suffix('_visitor')\n",
    "\n",
    "# Merge home and visitor team stats into a single row per game\n",
    "final_data = nba_data[['game_id', 'home_team_id', 'visitor_team_id', 'game_date', 'game_home_team_score', 'game_visitor_team_score']].drop_duplicates()\n",
    "final_data = final_data.merge(home_team_stats, left_on=['game_id', 'home_team_id'], right_on=['game_id_home', 'player_team_id_home'], how='left')\n",
    "final_data = final_data.merge(visitor_team_stats, left_on=['game_id', 'visitor_team_id'], right_on=['game_id_visitor', 'player_team_id_visitor'], how='left')\n",
    "\n",
    "# Drop redundant columns\n",
    "final_data.drop(['game_id_home', 'player_team_id_home', 'game_id_visitor', 'player_team_id_visitor'], axis=1, inplace=True)\n",
    "\n",
    "# Rename columns to remove 'player_' prefix\n",
    "final_data = final_data.rename(columns=lambda x: x.replace('player_', ''))\n",
    "\n",
    "# Calculate point spread\n",
    "final_data['point_spread'] = final_data['game_home_team_score'] - final_data['game_visitor_team_score']\n",
    "\n",
    "# Add a column to indicate the game winner\n",
    "final_data['game_winner'] = final_data.apply(lambda row: 'HOME' if row['game_home_team_score'] > row['game_visitor_team_score'] else 'VISITOR', axis=1)\n",
    "\n",
    "# Final structured dataset\n",
    "final_dataset = final_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97bbed7-4127-42e4-b2cd-d168312d2c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(final_dataset)\n",
    "\n",
    "# Export to CSV\n",
    "csv_filename = './nba_games_formatted.csv'\n",
    "df.to_csv(csv_filename, index=False)\n",
    "\n",
    "csv_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748ba708-3c99-469b-9da8-dcc6a7ef3edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = './nba_games_formatted.csv'  # Replace with your dataset's path\n",
    "nba_data = pd.read_csv(file_path)\n",
    "\n",
    "# Convert 'game_date' to datetime format\n",
    "nba_data['game_date'] = pd.to_datetime(nba_data['game_date']).dt.date\n",
    "\n",
    "# List of statistics for which to calculate 10-day averages\n",
    "stats_columns = ['ast', 'blk', 'dreb', 'fg3_pct', 'fg_pct', 'ft_pct', 'oreb', 'pf', 'pts', 'reb', 'stl', 'turnover']\n",
    "\n",
    "# Function to calculate 10-day averages\n",
    "def calculate_10_day_averages(row, data):\n",
    "    game_date = row['game_date']\n",
    "    home_team_id = row['home_team_id']\n",
    "    visitor_team_id = row['visitor_team_id']\n",
    "\n",
    "    # Filter for the last 10 games for each team before the game date\n",
    "    last_10_home = data[((data['home_team_id'] == home_team_id) | (data['visitor_team_id'] == home_team_id)) & \n",
    "                        (data['game_date'] < game_date)].sort_values(by='game_date', ascending=False).head(10)\n",
    "    last_10_visitor = data[((data['home_team_id'] == visitor_team_id) | (data['visitor_team_id'] == visitor_team_id)) & \n",
    "                           (data['game_date'] < game_date)].sort_values(by='game_date', ascending=False).head(10)\n",
    "\n",
    "    # Calculate averages for each team\n",
    "    averages = {}\n",
    "    for stat in stats_columns:\n",
    "        # Home team averages\n",
    "        home_stat_home_games = last_10_home[last_10_home['home_team_id'] == home_team_id][f\"{stat}_home\"]\n",
    "        home_stat_visitor_games = last_10_home[last_10_home['visitor_team_id'] == home_team_id][f\"{stat}_visitor\"]\n",
    "        averages[f\"{stat}_home_10day_avg\"] = pd.concat([home_stat_home_games, home_stat_visitor_games]).mean()\n",
    "\n",
    "        # Visitor team averages\n",
    "        visitor_stat_home_games = last_10_visitor[last_10_visitor['home_team_id'] == visitor_team_id][f\"{stat}_home\"]\n",
    "        visitor_stat_visitor_games = last_10_visitor[last_10_visitor['visitor_team_id'] == visitor_team_id][f\"{stat}_visitor\"]\n",
    "        averages[f\"{stat}_visitor_10day_avg\"] = pd.concat([visitor_stat_home_games, visitor_stat_visitor_games]).mean()\n",
    "\n",
    "    return averages\n",
    "\n",
    "# Calculating 10-day averages and appending to the dataset\n",
    "for index, row in nba_data.iterrows():\n",
    "    averages = calculate_10_day_averages(row, nba_data)\n",
    "    nba_data.loc[index, averages.keys()] = averages.values()\n",
    "\n",
    "# Display the updated dataset\n",
    "nba_data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b37d53-213f-4973-814b-7194412050ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Export to CSV\n",
    "csv_filename = './nba_games_formatted_with_10_day_averages.csv'\n",
    "nba_data.to_csv(csv_filename, index=False)\n",
    "\n",
    "csv_filename"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
